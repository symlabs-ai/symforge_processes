# ğŸ”¹ BDD Subetapa 5: Skeleton de AutomaÃ§Ã£o

## ğŸ¯ PropÃ³sito

Criar a **infraestrutura de testes BDD** que permitirÃ¡ ao time de desenvolvimento:
- ComeÃ§ar o ciclo TDD imediatamente (Red-Green-Refactor)
- Executar features Gherkin como testes automatizados
- Validar comportamentos conforme implementaÃ§Ã£o avanÃ§a

Esta etapa **NÃƒO implementa** os testes â€” apenas prepara o esqueleto.

---

## âš™ï¸ Entradas e SaÃ­das

| Tipo | Artefato | DescriÃ§Ã£o |
|------|----------|-----------|
| **Entrada** | `specs/bdd/**/*.feature` | Features Gherkin finalizadas |
| **SaÃ­da** | `tests/bdd/test_*_steps.py` | Step definitions (vazias) |
| **SaÃ­da** | `tests/bdd/conftest.py` | Fixtures pytest |
| **SaÃ­da** | `pytest.ini` | ConfiguraÃ§Ã£o de marcadores |
| **SaÃ­da** | `requirements-dev.txt` | DependÃªncias de teste |

---

## ğŸ§© Componentes do Skeleton

### 1. **Step Definitions** (`test_*_steps.py`)

Arquivos que vinculam steps Gherkin a cÃ³digo Python.

**Estrutura base:**

```python
# tests/bdd/test_forge_chat_steps.py

import pytest
from pytest_bdd import scenarios, given, when, then, parsers

# ===========================
# IMPORTANTE: Marcar como skip
# ===========================
pytestmark = pytest.mark.skip("BDD (Forge chat) pendente de implementaÃ§Ã£o")

# ===========================
# Vincular feature Gherkin
# ===========================
scenarios("../../specs/bdd/10_forge_core/chat.feature")

# ===========================
# Step Definitions (vazias)
# ===========================

@given('que o Forge estÃ¡ configurado com o provedor "echo"', target_fixture="forge_client")
def forge_with_echo_provider():
    """
    TODO (TDD): Implementar configuraÃ§Ã£o do Forge com provedor echo.

    Quando implementar:
    1. Remover pytest.mark.skip do topo do arquivo
    2. Importar ForgeClient
    3. Retornar instÃ¢ncia configurada

    Exemplo:
        from forge import ForgeClient
        return ForgeClient(provider="echo")
    """
    pytest.skip("Aguardando implementaÃ§Ã£o (TDD)")

@when(parsers.parse('envio a mensagem "{message}"'), target_fixture="response")
def send_message(forge_client, message):
    """
    TODO (TDD): Implementar envio de mensagem.

    Quando implementar:
        return forge_client.chat(message)
    """
    pytest.skip("Aguardando implementaÃ§Ã£o (TDD)")

@then(parsers.parse('recebo uma resposta contendo "{text}"'))
def check_response_contains(response, text):
    """
    TODO (TDD): Validar conteÃºdo da resposta.

    Quando implementar:
        assert text in response.content
    """
    pytest.skip("Aguardando implementaÃ§Ã£o (TDD)")
```

**ConvenÃ§Ãµes de nomenclatura:**

```
Feature: specs/bdd/10_forge_core/chat.feature
  â†“
Step file: tests/bdd/test_forge_chat_steps.py

Feature: specs/bdd/20_symclient_http/errors.feature
  â†“
Step file: tests/bdd/test_symclient_http_errors_steps.py
```

---

### 2. **Fixtures Compartilhadas** (`conftest.py`)

Fixtures reutilizÃ¡veis em todos os testes BDD.

```python
# tests/bdd/conftest.py

import pytest

# ===========================
# Contexto Compartilhado
# ===========================

@pytest.fixture
def context():
    """
    DicionÃ¡rio compartilhado entre steps de um cenÃ¡rio.

    Uso:
        @given(...)
        def some_step(context):
            context['user_id'] = 123

        @then(...)
        def another_step(context):
            assert context['user_id'] == 123
    """
    return {}

# ===========================
# ConfiguraÃ§Ãµes de Teste
# ===========================

@pytest.fixture
def forge_config():
    """
    ConfiguraÃ§Ã£o padrÃ£o do Forge para testes.

    TODO (TDD): Ajustar conforme implementaÃ§Ã£o real.
    """
    return {
        "provider": "echo",
        "timeout": 30,
        "log_level": "DEBUG"
    }

@pytest.fixture
def symclient_http_url():
    """
    URL base do SymClient HTTP para testes.

    Assume que SymClient estÃ¡ rodando localmente.
    """
    return "http://localhost:8000"

@pytest.fixture
def symclient_stdio_process():
    """
    TODO (TDD): Iniciar processo SymClient STDIO para testes.

    Quando implementar:
        import subprocess
        process = subprocess.Popen(["symclient", "stdio"])
        yield process
        process.terminate()
    """
    pytest.skip("SymClient STDIO nÃ£o implementado ainda")

# ===========================
# Hooks de Teste
# ===========================

def pytest_bdd_before_scenario(request, feature, scenario):
    """
    Executado antes de cada cenÃ¡rio.
    Ãštil para logging ou setup global.
    """
    print(f"\nâ–¶ï¸  CenÃ¡rio: {scenario.name}")

def pytest_bdd_after_scenario(request, feature, scenario):
    """
    Executado apÃ³s cada cenÃ¡rio.
    Ãštil para cleanup ou mÃ©tricas.
    """
    print(f"âœ… CenÃ¡rio concluÃ­do: {scenario.name}")

def pytest_bdd_step_error(request, feature, scenario, step, step_func, step_func_args, exception):
    """
    Executado quando um step falha.
    """
    print(f"âŒ Step falhou: {step.name}")
    print(f"   Erro: {exception}")
```

---

### 3. **ConfiguraÃ§Ã£o pytest** (`pytest.ini`)

Define marcadores (tags) e comportamento dos testes.

```ini
# pytest.ini

[pytest]
# ===========================
# Marcadores (Tags)
# ===========================
markers =
    # Tiers de execuÃ§Ã£o
    ci_fast: Testes rÃ¡pidos (mocks, sem deps externas)
    ci_int: Testes de integraÃ§Ã£o (provedores locais)
    e2e: Testes end-to-end (deps externas)

    # DomÃ­nios
    sdk: Forge SDK Python
    server: SymClient (HTTP ou STDIO)
    http: Protocolo HTTP
    stdio: Protocolo STDIO/JSON-RPC

    # Capacidades
    contexto: GestÃ£o de sessÃ£o/contexto
    streaming: Respostas em stream
    capability_tool_calling: Tool calling / function calling
    fallback: EstratÃ©gias de fallback

    # IntegraÃ§Ãµes
    mcp: IntegraÃ§Ã£o MCP Tecnospeed
    broker: Roteamento via LLM Broker
    tecnospeed: Ecossistema Tecnospeed

    # Categorias
    observabilidade: Logs, mÃ©tricas, traces
    seguranca: Auth, redaction, rate limit
    erro: CenÃ¡rios de tratamento de erro

# ===========================
# Comportamento de Testes
# ===========================
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# OpÃ§Ãµes padrÃ£o
addopts =
    -v
    --strict-markers
    --tb=short
    --disable-warnings

# ===========================
# BDD EspecÃ­fico
# ===========================
bdd_features_base_dir = specs/bdd/
```

---

### 4. **DependÃªncias de Teste** (`requirements-dev.txt`)

```txt
# requirements-dev.txt

# Framework de testes
pytest>=7.4.0
pytest-cov>=4.1.0
pytest-html>=3.2.0

# BDD
pytest-bdd>=6.1.1

# Linting e formataÃ§Ã£o
black>=23.0.0
flake8>=6.0.0
mypy>=1.4.0

# Type stubs
types-requests>=2.31.0

# UtilitÃ¡rios de teste
faker>=19.0.0           # GeraÃ§Ã£o de dados fake
responses>=0.23.0       # Mock de requisiÃ§Ãµes HTTP
pytest-mock>=3.11.0     # Mocking avanÃ§ado
```

---

## ğŸ“‹ Checklist de CriaÃ§Ã£o de Skeleton

### Para Cada Feature Gherkin

```markdown
- [ ] Criar arquivo `tests/bdd/test_[nome]_steps.py`
- [ ] Adicionar `pytestmark = pytest.mark.skip(...)`
- [ ] Vincular feature: `scenarios("../../specs/bdd/[path]/[feature].feature")`
- [ ] Criar step definitions vazias para cada DADO/QUANDO/ENTÃƒO
- [ ] Adicionar docstrings com TODO e exemplos
- [ ] Testar que arquivo roda sem erros: `pytest tests/bdd/test_[nome]_steps.py -v`
```

---

## ğŸ§ª ValidaÃ§Ã£o do Skeleton

### Teste 1: Arquivos Reconhecidos

```bash
# Pytest deve descobrir todos os testes BDD
pytest --collect-only tests/bdd/

# SaÃ­da esperada:
# <Module tests/bdd/test_forge_chat_steps.py>
#   <Function test_enviar_mensagem_simples[...]>
# <Module tests/bdd/test_forge_sessao_steps.py>
#   <Function test_preservar_contexto[...]>
# ...
```

### Teste 2: ExecuÃ§Ã£o com Skip

```bash
# Todos os testes devem ser pulados (ainda nÃ£o implementados)
pytest tests/bdd/ -v

# SaÃ­da esperada:
# tests/bdd/test_forge_chat_steps.py::test_enviar... SKIPPED (BDD pendente)
# tests/bdd/test_forge_sessao_steps.py::test_preservar... SKIPPED (BDD pendente)
# ...
# =================== X skipped in 0.5s ===================
```

### Teste 3: Marcadores Funcionando

```bash
# Filtrar por tag
pytest -m ci_fast tests/bdd/ --collect-only

# Deve listar apenas features com @ci-fast
```

---

## ğŸ¯ Exemplo: Skeleton para Feature de SessÃ£o

**Feature:**
```gherkin
# specs/bdd/10_forge_core/sessao.feature

@sdk @contexto @ci-fast
FUNCIONALIDADE: GestÃ£o de sessÃµes
  ...

  CENÃRIO: Preservar histÃ³rico na sessÃ£o
    DADO um session_id "abc123"
    E o Forge configurado com provedor "echo"
    QUANDO envio mensagem "OlÃ¡"
    E envio mensagem "Tudo bem?"
    ENTÃƒO a resposta final considera o histÃ³rico
```

**Skeleton:**
```python
# tests/bdd/test_forge_sessao_steps.py

import pytest
from pytest_bdd import scenarios, given, when, then, parsers

pytestmark = pytest.mark.skip("BDD (sessÃ£o) pendente de implementaÃ§Ã£o")

scenarios("../../specs/bdd/10_forge_core/sessao.feature")

@given(parsers.parse('um session_id "{session_id}"'), target_fixture="session_id")
def create_session_id(session_id):
    """TODO: Retornar session_id para uso nos prÃ³ximos steps."""
    pytest.skip("Aguardando implementaÃ§Ã£o")

@given('o Forge configurado com provedor "echo"', target_fixture="forge_client")
def forge_with_echo(session_id):
    """TODO: Retornar ForgeClient configurado com session_id."""
    pytest.skip("Aguardando implementaÃ§Ã£o")

@when(parsers.parse('envio mensagem "{message}"'))
def send_message_to_session(forge_client, message, context):
    """
    TODO: Enviar mensagem e guardar resposta em context.

    Quando implementar:
        response = forge_client.chat(message)
        context.setdefault('responses', []).append(response)
    """
    pytest.skip("Aguardando implementaÃ§Ã£o")

@then('a resposta final considera o histÃ³rico')
def check_response_has_context(context):
    """
    TODO: Validar que a Ãºltima resposta tem contexto das anteriores.

    Quando implementar:
        responses = context['responses']
        assert len(responses) >= 2
        # Validar que segunda resposta menciona primeira mensagem
    """
    pytest.skip("Aguardando implementaÃ§Ã£o")
```

---

## âœ… CritÃ©rios de Qualidade (DoD)

- [ ] Step file criado para cada feature Gherkin
- [ ] Todos os steps tÃªm docstrings com TODO
- [ ] Todos marcados com `pytest.mark.skip`
- [ ] `conftest.py` criado com fixtures base
- [ ] `pytest.ini` configurado com marcadores
- [ ] `requirements-dev.txt` atualizado
- [ ] ValidaÃ§Ã£o: `pytest --collect-only tests/bdd/` funciona
- [ ] ValidaÃ§Ã£o: `pytest tests/bdd/ -v` mostra todos skipped

---

## ğŸ”„ PrÃ³ximo Passo

Com o skeleton pronto, avance para:

**Subetapa 6: Handoff para TDD** (`etapa_06_handoff_tdd.md`)

---

**Author**: Forge Framework Team
**Version**: 1.0
**Date**: 2025-11-04
